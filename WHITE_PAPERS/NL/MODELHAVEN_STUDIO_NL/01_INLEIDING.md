<a id="inleiding"></a>
## Inleiding

Systemen die gebruikmaken van artificiële intelligentie zijn niet langer neutrale hulpmiddelen. Zij beïnvloeden wie zichtbaar is, wie kan spreken, wie wordt gerepresenteerd en onder welke voorwaarden creatie, expressie en interactie plaatsvinden. Daarmee oefenen deze systemen macht uit — vaak impliciet, nauwelijks herroepbaar en zelden expliciet ontworpen.

In de huidige praktijk wordt deze macht voornamelijk begrensd via beleid, moderatie en juridische voorwaarden **achteraf**. Ethiek verschijnt als correctiemechanisme: wanneer schade al is ontstaan, wanneer reputaties onder druk staan, of wanneer wetgeving dwingt tot ingrijpen. Deze benadering schiet tekort. Zij adresseert symptomen, niet de onderliggende systeemlogica die bepaalt wat een systeem mogelijk maakt, normaliseert of structureel faciliteert.

Tegelijkertijd is het belangrijk te erkennen dat **misbruik van digitale technologie geen nieuw fenomeen is**. Al sinds de vroege dagen van het internet bestaan er voorbeelden waarin identiteit wordt gemanipuleerd, toegeëigend of geëxploiteerd. In de jaren negentig werd dit thema zichtbaar in populaire cultuur, zoals in de film *The Net*, waarin digitale identiteitsmanipulatie centraal staat. Ook buiten fictie zijn er vroege voorbeelden waarin technologische ontwikkelingen bestaande machtsverhoudingen rond zichtbaarheid en toestemming op scherp zetten.

De verspreiding van gemanipuleerde beelden van publieke figuren — destijds nog niet aangeduid als ‘deepfakes’ — werd begin jaren 2000 vaak geframed als individueel schandaal. Wat toen werd gepresenteerd als moreel falen van het individu, wordt inmiddels breder erkend als een **structureel probleem van technologie, distributie en ontbrekende bescherming**.

Artificiële intelligentie heeft dit probleem niet gecreëerd, maar **wel drastisch versneld, geschaald en gedemocratiseerd**. Waar identiteitsmisbruik eerder incidenteel en technisch complex was, is het nu reproduceerbaar, goedkoop en moeilijk te herleiden. Daarmee is het verschoven van een uitzonderingsprobleem naar een **systemische ontwerpfout**.

Binnen journalistiek, academie en beleid groeit het besef dat deze problematiek niet primair draait om AI als technologie, maar om **macht, concentratie en verantwoordelijkheid**. Analyses beschrijven hoe AI-systemen zijn ingebed in bredere economische en politieke machtsstructuren, waarbij schaal en extractie vaak zwaarder wegen dan bescherming of maatschappelijke legitimiteit. Vanuit academische hoek wordt parallel hieraan gewezen op het ontbreken van consistente ethische grondslagen in AI-ontwerp.

Deze ontwikkeling bevestigt voor de auteur de noodzaak om actief bij te dragen aan ontwerpbenaderingen die veiligheid, toestemming en verantwoordelijkheid niet als bijzaak behandelen, maar als fundamentele voorwaarden voor digitale systemen.


<a id="positionering-en-interpretatie"></a>
## Positionering en interpretatie

Dit document beschrijft geen afgerond product en geen volledig uitgewerkt platform. Het beschrijft een **ontwerpbenadering en systeempositie**. ModelHaven Studio is op dit moment een te bouwen concept, geen bestaande infrastructuur.

De auteur is zich ervan bewust dat de hier beschreven principes — zoals consent-architectuur, identiteitsbescherming en fail-closed veiligheid — ook door anderen kunnen worden opgepakt, aangepast of geïmplementeerd. Dat is geen risico, maar een gegeven. Ethische systemen zijn nooit neutraal en nooit identiek: zij worden onvermijdelijk gevormd door menselijke keuzes, context en verantwoordelijkheid.

Zelfs wanneer derden vergelijkbare uitgangspunten hanteren, zullen uitwerkingen verschillen. Niet vanwege technische beperkingen, maar omdat ethiek zich niet laat kopiëren zonder interpretatie. Dit document pretendeert daarom geen universele blauwdruk te zijn, maar een **expliciete en toetsbare positionering**.

De in dit whitepaper beschreven concepten zijn bedoeld als **grondslag voor verdere ontwikkeling, toetsing en — waar passend — licentieerbare toepassing**, zonder dat daarmee wordt gesuggereerd dat één enkele implementatie de enige juiste is.

De hoofdstukken die volgen beschrijven hoe ModelHaven Studio functioneert als **operationele vertaling van UCSF**: van normatief kader naar systeemgedrag. Niet om te overtuigen, maar om zichtbaar te maken welke keuzes noodzakelijk zijn wanneer toestemming, veiligheid en verantwoordelijkheid geen optionele waarden zijn, maar structurele vereisten.
