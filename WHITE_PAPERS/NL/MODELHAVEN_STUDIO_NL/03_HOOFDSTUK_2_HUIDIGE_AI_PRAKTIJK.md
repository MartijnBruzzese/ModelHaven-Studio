<a id="h2"></a>
## Hoofdstuk 2 — Van Moderatie achteraf naar Ontwerpverantwoordelijkheid

Veel hedendaagse AI-systemen presenteren ethiek en veiligheid als een laag die **bovenop** bestaande functionaliteit wordt geplaatst. Grenzen verschijnen pas wanneer maatschappelijke druk ontstaat, wanneer regelgeving dwingt tot aanpassing, of wanneer reputatierisico’s zichtbaar worden. In die benadering wordt ethiek een correctiemechanisme achteraf, geen structureel ontwerpfundament.

ModelHaven Studio vertrekt vanuit de stelling dat deze aanpak principieel en praktisch tekortschiet.

---

<a id="h2-1"></a>
### 2.1 Moderatie als symptoombestrijding en inefficiëntie

Binnen veel generieke AI-systemen vindt moderatie plaats **voorafgaand aan output**, zoals bij ChatGPT en vergelijkbare modellen. Deze vorm van moderatie is technisch verfijnd en juridisch begrijpelijk, maar laat weinig ruimte voor nuance of context.

Hoewel prompts inhoudelijk en ethisch verdedigbaar kunnen zijn — en door een mens met normale morele afweging zonder bezwaar zouden worden beoordeeld — worden zij door het systeem soms alsnog als ongepast geclassificeerd. De generatie wordt dan abrupt afgebroken, zonder inhoudelijke toelichting of contextuele differentiatie.

Dit heeft meerdere gevolgen:

- creatieve en onderzoeksmatige processen lopen vast zonder duidelijke reden;
- gebruikers worden gedwongen tot herhaalde herformuleringen;
- en het systeem start telkens nieuwe generatiepogingen die voortijdig worden beëindigd.

Deze dynamiek is niet alleen frustrerend, maar ook **inefficiënt**. Elke heriteratie activeert opnieuw rekenkracht, energieverbruik en infrastructuur, zonder dat er output wordt gegenereerd. Extreme risicomijding leidt zo paradoxaal genoeg tot **onnodig verhoogd resourceverbruik**.

De gebruiker ervaart dit als:

- rigide grenzen zonder context;
- weigeringen zonder zichtbare ontwerpkeuze;
- en een systeem dat geen onderscheid maakt tussen potentieel risico en daadwerkelijke schade.

Deze benadering voldoet aan regelgeving zoals de AVG, GDPR en de AI Act, maar zij **vervangt ethiek door compliance**. Het resultaat is geen intrinsiek veilig systeem, maar een beperkt systeem dat primair is ingericht op aansprakelijkheidsvermijding — met technische en ecologische inefficiëntie als neveneffect.

---

<a id="h2-2"></a>
### 2.2 Begrenzing na maatschappelijke kritiek: het voorbeeld Grok AI

Aan de andere kant van het spectrum bevinden zich systemen die aanvankelijk permissiever zijn ingericht en waarvan de ethische begrenzing gaandeweg wordt aangepast onder invloed van maatschappelijke kritiek, publieke discussie en regulatoire druk. Grok AI is een illustratief voorbeeld van deze dynamiek.

Binnen Grok zijn in verschillende fases en contexten zogeheten modi geïntroduceerd — onder meer aangeduid als *Spicy* en *Spicy+* — waarin volwassen of suggestieve vormen van expressie ruimer werden toegestaan dan in veel andere generatieve AI-systemen. Deze modi betekenden geen volledige afwezigheid van veiligheidsmechanismen; filters en beperkingen bleven bestaan, met name rond expliciet illegale of extreme inhoud.

Tegelijkertijd lagen de **interpretatiedrempels en contextuele strengheid** in deze lagen aantoonbaar anders dan in standaardmodi. Niet omdat ethiek werd opgeheven, maar omdat zij **anders werd afgewogen**: met meer ruimte voor expressie en minder voorafgaande blokkade.

Na publieke en politieke kritiek zijn deze grenzen opnieuw aangescherpt, met name in gratis of breed toegankelijke varianten van het systeem. In sommige gevallen zijn functionaliteiten beperkt, aangepast of regionaal teruggeschroefd. Deze ontwikkeling maakt zichtbaar dat ethische grenzen binnen dergelijke systemen **meebewegen met externe druk** en niet vanaf het begin architectonisch zijn vastgelegd.

De fundamentele vraag die hieruit voortkomt is niet of een systeem “ethisch” of “onethisch” is, maar **waar en hoe ethische grenzen worden bepaald**. Wanneer verschillen in begrenzing samenvallen met abonnementsstructuren of toegangsniveaus, ontstaat het risico dat ethiek wordt ervaren als gradueel, onderhandelbaar of afhankelijk van betalingsbereidheid.

ModelHaven Studio verwerpt deze benadering niet uit ideologische afkeer, maar uit ontwerpoverweging. Ethische grenzen moeten vooraf zijn vastgelegd en mogen niet primair reageren op publieke escalatie.

---

<a id="h2-3"></a>
### 2.3 Ontwerpgebreken én kwaadwillende intentie

In alle bekende gevallen van misbruik rond niet-consensuele beeldgeneratie — zowel bij minderjarigen als bij vrouwen — was sprake van **een combinatie van ontwerpgebreken en expliciet kwaadwillende intenties**.

Het bestaan van kwaadwillige gebruikers is geen hypothetisch risico, maar een gedocumenteerde realiteit. Tegelijkertijd verklaart dit misbruik niet volledig. Wanneer systemen die werken met beeld, identiteit en seksualiteit **geen fail-closed bescherming** hanteren, fungeren zij als vermenigvuldiger van bestaande kwaadwilligheid.

De misstanden zijn daarom niet het gevolg van uitsluitend individuele morele tekortkomingen, noch uitsluitend technische onvolkomenheden, maar van een **voorspelbare interactie tussen menselijk gedrag en systeemontwerp**.

Wat in de vroege ontwerpkeuzes van systemen zoals Grok ontbrak, is een structurele architectuur die:

- bij twijfel over leeftijd of identiteit automatisch stopt;
- bij ontbreken van aantoonbare toestemming geen generatie toestaat;
- en bij patroonvorming van misbruik niet optimaliseert, maar weigert.

Het ontbreken van consent tokens, intentiesensoren en automatische fail-closed mechanismen betekende dat kwaadwillende intenties niet werden gestopt waar dat ethisch noodzakelijk was, maar pas werden gecorrigeerd nadat schade zichtbaar werd.

ModelHaven Studio vertrekt vanuit de tegenovergestelde aanname:  
kwaadwillige intentie is een **ontwerpvoorwaarde**, geen randgeval.

---

<a id="h2-4"></a>
### 2.4 Ontwerpethiek en menselijke verantwoordelijkheid

Zowel overmatige vooraf-moderatie als permissiviteit met correctie achteraf vertrekken vanuit hetzelfde impliciete uitgangspunt: dat ethiek primair een gedragsprobleem van gebruikers is.

ModelHaven Studio hanteert een ander vertrekpunt:  
ethiek is een **ontwerpprobleem**.

Dit betekent dat:

- grenzen zichtbaar zijn in de architectuur zelf;
- niet alles wat technisch mogelijk is, wordt aangeboden;
- en weigering een expliciete, uitlegbare systeemuitkomst is.

In deze benadering blijft **menselijke verantwoordelijkheid leidend**. Automatisering ondersteunt, maar vervangt geen moreel oordeel.

Niet alles wat kan worden geautomatiseerd, **hoort** te worden geautomatiseerd.

---

<a id="h2-5"></a>
### 2.5 Technische infrastructuur als ethische factor

Ethische beoordeling van AI-systemen kan niet beperkt blijven tot inhoud en interactie. De **materiële infrastructuur** waarop deze systemen draaien — datacenters, energievoorziening, koeling en watergebruik — maakt integraal deel uit van hun impact.

Grootschalige AI-systemen verbruiken aanzienlijke hoeveelheden elektriciteit, grote volumes koelwater en fysieke infrastructuur met lokale gevolgen. Deze effecten zijn geen nevenverschijnselen, maar het directe gevolg van schaal- en ontwerpkeuzes.

Hoewel diepgaande analyse van deze impact buiten de scope van dit document valt, stelt ModelHaven Studio expliciet dat deze dimensie **niet buiten het ethische domein mag worden geplaatst**. Ethiek eindigt niet bij de interface.

---

<a id="h2-6"></a>
### 2.6 Ontwerp vóór regelgeving, niet erachteraan

Veel huidige AI-beperkingen zijn ingevoerd om te voldoen aan bestaande en aankomende regelgeving: AVG, GDPR, AI Act en aanverwante kaders. Deze regelgeving is noodzakelijk, maar fundamenteel **reactief**.

ModelHaven Studio kiest voor een andere houding:

- niet ontwerpen tot regelgeving dwingt;
- maar ontwerpen alsof regelgeving tekortschiet.

Wetgeving vormt een minimumgrens, geen moreel plafond.

---

<a id="h2-7"></a>
### 2.7 Samenvatting

Hoofdstuk 2 laat zien dat:

- moderatie achteraf ethiek niet vervangt;
- betaalde permissiviteit ethische grenzen kan uithollen;
- en regelgeving alleen onvoldoende richting geeft.

ModelHaven Studio positioneert ontwerpethiek als primaire verantwoordelijkheid. Niet om innovatie te blokkeren, maar om te voorkomen dat schaal, snelheid en marktlogica ethische erosie normaliseren.

In het volgende hoofdstuk wordt uitgewerkt hoe **consent, identiteit en intent** binnen deze ontwerpfilosofie functioneren als dragende systeemlagen.