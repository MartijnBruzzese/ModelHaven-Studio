---
layout: default
title: Core Principles â€” UCSF
---

# Core Principles  
### Universal Consent & Safety Framework (UCSF)

**Version:** v1.0  
**Last updated:** January 2026  
**Author:** Martijn Bruzzese

---

## Purpose

This document defines the core ethical principles underlying UCSF.

These principles are normative: they describe how systems *ought* to behave when consent, identity, safety, and power asymmetry are treated as design responsibilities rather than policy afterthoughts.

They do not prescribe implementation.

---

## 1. Consent Is a Condition, Not an Event

Consent is not a one-time checkbox.

It is:

- contextual  
- revocable  
- continuous  
- dependent on clarity and agency  

Systems must treat consent as an ongoing state rather than a transactional moment.

Absence of consent defaults to refusal.

---

## 2. Safety Is a Design Responsibility

Safety must be embedded at the architectural level.

It is not achieved through moderation alone.

Systems must be designed to:

- prevent foreseeable harm  
- fail closed under uncertainty  
- avoid optimizing for engagement at the expense of protection  

Safety is not reactive.

---

## 3. Ethical Refusal Is a Valid Outcome

Not all technically possible actions should be permitted.

Systems must retain the capacity to refuse requests that violate:

- consent  
- identity integrity  
- safety boundaries  
- power asymmetries  

Refusal must be explicit, explainable, and consistent.

---

## 4. Power Requires Responsibility

Every system concentrates power:

- over visibility  
- over representation  
- over access  
- over interaction  

Power without accountability leads to harm.

UCSF asserts that those who design and operate systems carry responsibility for their structural effects.

---

## 5. Repair Is an Ethical Obligation

When harm occurs, responsibility does not end at prevention.

Systems and institutions must support:

- acknowledgement  
- remediation  
- transparency  
- learning  

Repair is part of ethical design, not a reputational afterthought.

---

## 6. Human Oversight Must Remain Meaningful

Automation must not replace moral judgment.

Human involvement is required where:

- consent is ambiguous  
- harm is plausible  
- identity is at stake  
- vulnerability is present  

Delegating ethical decisions entirely to automated systems is itself an ethical failure.

---

## 7. Non-Human Life Is Morally Relevant

UCSF recognizes that ethical systems cannot be limited to human users alone.

Animals and vulnerable non-human beings must not be exposed to exploitation or harm through digital systems.

Their protection is treated as a design constraint, not an optional feature.

---

## 8. Environmental Limits Are Design Constraints

Large-scale digital systems consume:

- energy  
- water  
- physical infrastructure  

These impacts are ethical considerations, not externalities.

UCSF treats environmental pressure as a first-class design factor rather than a secondary operational concern.

---

## 9. Ethics Must Be Architectural

Ethical intent without system-level enforcement is insufficient.

Values must be reflected in:

- structural boundaries  
- interaction constraints  
- default behaviors  
- governance models  

Ethics belongs in architecture, not only in policy documents.

---

## Positioning Note

UCSF does not claim universal authority.

It offers an explicit ethical position intended for:

- peer review  
- interdisciplinary discussion  
- responsible adaptation  

Agreement is not required. Transparency is.

---

*These principles define UCSF v1.0 and will not be substantively altered without formal versioning.*