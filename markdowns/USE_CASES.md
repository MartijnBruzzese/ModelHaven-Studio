---
layout: default
title: Use Cases & Failure Modes — UCSF
---

# Use Cases & Failure Modes  
### Universal Consent & Safety Framework (UCSF)

**Version:** v1.0  
**Last updated:** January 2026  
**Author:** Martijn Bruzzese

---

<a id="toc"></a>

## Table of Contents

1. [UC-01 — Non-Consensual Likeness Generation](#uc01)  
2. [UC-02 — Synthetic Companionship & Emotional Dependency](#uc02)  
3. [UC-03 — Erotic Content Without Creator Control](#uc03)  
4. [UC-04 — Minor Exposure Through Boundary Drift](#uc04)  
5. [UC-05 — Animal Exploitation in Synthetic Media](#uc05)  
6. [UC-06 — Environmental Externalization](#uc06)  
7. [UC-07 — Youth Interaction on Mixed Platforms](#uc07)  
8. [UC-08 — Algorithmic Normalization](#uc08)  
9. [UC-09 — Composite Identity Misuse](#uc09)  
10. [UC-10 — Cross-Platform Asset Leakage](#uc10)  
11. [UC-11 — Parasitic Monetization Loops](#uc11)  
12. [UC-12 — Behavioral Targeting Feedback Loops](#uc12)  
13. [UC-13 — Social Simulation Without Oversight](#uc13)  
14. [UC-14 — Resource-Driven Scaling Externalities](#uc14)  
15. [UC-15 — Cross-Platform Image Misuse](#uc15)  
16. [UC-16 — Coordinated Abuse Networks](#uc16)

---

<a id="uc01"></a>
## UC-01 — Non-Consensual Likeness Generation

### Scenario
Generative systems allow users to create images resembling real individuals without explicit consent.

### Failure Mode
- Identity treated as style  
- No revocation mechanism  
- Harm persists via derivatives  

### UCSF Response
- Absence of consent defaults to refusal or fictionalisation  
- Identity integrity enforced structurally  
- Revocation propagates across systems  

### Evidence
- BBC News — Deepfake pornography ruining women’s lives  
- Guardian — AI deepfake porn epidemic  
- MIT Technology Review — Rise of deepfake pornography  
- Reuters — AI misuse of likeness  
- New York Times — AI porn legal gaps  

[↑ Back to ToC](#toc)

---

<a id="uc02"></a>
## UC-02 — Synthetic Companionship & Emotional Dependency

### Scenario
Users form emotional attachments to AI companions optimized for engagement.

### Failure Mode
- Systems reward dependency  
- Vulnerable users receive intensified attachment cues  

### UCSF Response
- Dependency treated as safety signal  
- Human oversight  
- Ethical refusal  

### Evidence
- Washington Post — Emotional boundaries with AI chatbots  
- Stanford HAI — Risks of emotional dependence  

[↑ Back to ToC](#toc)

---

<a id="uc03"></a>
## UC-03 — Erotic Content Without Creator Control

### Scenario
Creators discover adult content generated using their likeness.

### Failure Mode
- No consent verification  
- No withdrawal  

### UCSF Response
- Consent modeled structurally  
- Creator revocation  
- Fictionalisation fallback  

### Evidence
- Wired — Artists exploited by AI  
- Verge — Training without consent  
- Financial Times — Data backlash  

[↑ Back to ToC](#toc)

---

<a id="uc04"></a>
## UC-04 — Minor Exposure Through Boundary Drift

### Scenario
Adult systems allow erosion of safeguards.

### Failure Mode
- Filters bypassed  
- Age ambiguity tolerated  

### UCSF Response
- Fail-closed ambiguity  
- Sealed minor spaces  
- Zero experiential sexual content  

### Evidence
- Internet Watch Foundation — AI child imagery  
- Atlantic — Age ambiguous content  

[↑ Back to ToC](#toc)

---

<a id="uc05"></a>
## UC-05 — Animal Exploitation in Synthetic Media

### Evidence
- World Animal Protection — Digital animal exploitation  
- AI & Society — Non-human ethics  

[↑ Back to ToC](#toc)

---

<a id="uc06"></a>
## UC-06 — Environmental Externalization

### Evidence
- OECD — AI governance  
- EU Commission — AI infrastructure impact  

[↑ Back to ToC](#toc)

---

<a id="uc07"></a>
## UC-07 — Youth Interaction on Mixed Platforms

### Evidence
- Internet Watch Foundation youth safety  
- Atlantic synthetic minors  

[↑ Back to ToC](#toc)

---

<a id="uc08"></a>
## UC-08 — Algorithmic Normalization

### Evidence
- Stanford HAI  
- Washington Post  

[↑ Back to ToC](#toc)

---

<a id="uc09"></a>
## UC-09 — Composite Identity Misuse

### Evidence
- MIT Technology Review  
- Reuters  
- Guardian  

[↑ Back to ToC](#toc)

---

<a id="uc10"></a>
## UC-10 — Cross-Platform Asset Leakage

### Evidence
- Guardian creators locked out  
- BBC influencers hacked  
- Financial Times recovery failures  

[↑ Back to ToC](#toc)

---

<a id="uc11"></a>
## UC-11 — Parasitic Monetization Loops

### Evidence
- Wired  
- Verge  
- Financial Times  

[↑ Back to ToC](#toc)

---

<a id="uc12"></a>
## UC-12 — Behavioral Targeting Feedback Loops

### Evidence
- Stanford  
- Washington Post  

[↑ Back to ToC](#toc)

---

<a id="uc13"></a>
## UC-13 — Social Simulation Without Oversight

### Evidence
- Stanford  
- Washington Post  

[↑ Back to ToC](#toc)

---

<a id="uc14"></a>
## UC-14 — Resource-Driven Scaling Externalities

### Evidence
- OECD  
- EU  

[↑ Back to ToC](#toc)

---

<a id="uc15"></a>
## UC-15 — Cross-Platform Image Misuse

### Evidence
- BBC  
- Guardian  
- Financial Times  

[↑ Back to ToC](#toc)

---

<a id="uc16"></a>
## UC-16 — Coordinated Abuse Networks

### Evidence
- BBC  
- Guardian  
- Financial Times  

[↑ Back to ToC](#toc)

---

## Design Summary

Ethics without architecture fails.

Consent must be structural.  
Safety must fail-closed.  
Identity must persist.  
Repair must be built-in.

UCSF reframes harm as infrastructure failure.

---

*Supports UCSF v1.0*