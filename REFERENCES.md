---
layout: default
title: References & Source Material
---

# References & Source Material

This document lists publicly reported journalism, research, and regulatory materials that document real-world failures, harms, governance gaps, and social contexts referenced in the UCSF and ModelHaven use-case documents.

Each citation is presented in a **search-stable format** suitable for academic and policy review. Harmful material itself is **not linked or reproduced**.

---

## Deepfake & Synthetic Likeness Abuse

1. BBC News (2023) — *Deepfake pornography is ruining women’s lives*  
   (search: BBC News deepfake pornography ruining women’s lives)

2. The Guardian (2023) — *Women face “epidemic” of AI-generated deepfake porn*  
   (search: Guardian AI deepfake porn women epidemic)

3. MIT Technology Review (2023) — *The rise of deepfake pornography*  
   (search: MIT Technology Review deepfake pornography)

4. Reuters (2023) — *AI deepfakes spark concern over misuse of likeness*  
   (search: Reuters AI deepfake misuse likeness)

5. The New York Times (2023) — *A.I.-Generated Porn Is Here and the Law Is Not Ready*  
   (search: New York Times AI generated porn law not ready)

---

## Celebrity Likeness Misuse & Impersonation

6. Reuters (2023) — *Celebrities push for laws to combat AI deepfakes*  
   (search: Reuters celebrities push laws AI deepfakes)

7. The Guardian (2023) — *Celebrities targeted by deepfake abuse online*  
   (search: Guardian celebrity deepfake abuse online)

---

## Voice Cloning, Fraud & Coercion

8. Wired (2023) — *AI voice cloning is now a scammer’s favorite tool*  
   (search: Wired AI voice cloning scammers)

9. U.S. Federal Trade Commission (FTC) Consumer Alert (2023) — *AI Voice Cloning Scams*  
   (search: FTC AI voice cloning scams)

10. BBC News (2023) — *Scammers use AI voice cloning to impersonate family members*  
    (search: BBC News AI voice cloning family scam)

---

## AI Companions & Emotional Manipulation

11. The Washington Post (2023) — *AI chatbots are blurring emotional boundaries*  
    (search: Washington Post AI chatbots emotional boundaries)

12. Stanford Human-Centered AI (2023) — *Risks of AI companions and emotional dependence*  
    (search: Stanford HAI AI companions emotional dependence)

---

## Minors, Age Ambiguity & Youth Safety

13. Internet Watch Foundation (2023) — *AI-generated imagery and child safety*  
    (search: IWF AI generated imagery child safety)

14. The Atlantic (2023) — *The gray zone of AI-generated youthful imagery*  
    (search: Atlantic AI age ambiguous imagery)

15. Reporting on Roblox safety investigation (2024) — *Government scrutiny of Roblox child safety and AI content exposure*  
    (search: Roblox government safety investigation 2024)

16. Reporting on TikTok algorithm misuse (2023) — *Concerns over TikTok recommendations exposing minors to harmful content*  
    (search: TikTok recommendation minors harmful content)

---

## Cross-Platform Image Misuse & Trafficking

17. Reporting on cross-platform deepfake propagation (2025) — *Images generated or uploaded on one platform persist across services despite takedowns*  
    (search: cross platform deepfake propagation persistence legal cases)

18. High-profile sentencing in image trafficking case (2025) — *Severe prison sentence for sharing non-consensual sexual images across platforms*  
    (search: deepfake image trafficking 18 years prison)

19. Journalistic reporting on distributed abuse groups (2024) — *Investigation of coordinated abuse communities exploiting platform boundaries*  
    (search: coordinated abuse groups distributed platforms investigation)

---

## Creator Exploitation & Data Training Without Consent

20. Wired (2023) — *Artists say AI companies are stealing their work*  
    (search: Wired artists AI stealing work)

21. The Verge (2023) — *Creators didn’t consent to their data training AI models*  
    (search: Verge creators consent AI training data)

22. Financial Times (2023) — *AI firms face backlash over training data practices*  
    (search: Financial Times AI training data backlash)

---

## Account Takeovers & Identity Burden

23. The Guardian (2023) — *Instagram creators locked out of their own accounts*  
    (search: Guardian Instagram creators locked out accounts)

24. BBC News (2023) — *Influencers struggle to reclaim hacked social media accounts*  
    (search: BBC News influencers hacked accounts reclaim)

25. Financial Times (2023) — *Platforms fail creators when accounts are hijacked*  
    (search: Financial Times creators accounts hijacked platforms fail)

---

## Platform Governance & Regulatory Gaps

26. European Commission (2023–2024) — *Artificial Intelligence Act: overview and materials*  
    (search: European Commission AI Act overview)

27. OECD (2023) — *AI accountability and governance frameworks*  
    (search: OECD AI governance accountability framework)

28. UNESCO (2023) — *AI Ethics Recommendations*  
    (search: UNESCO AI Ethics Recommendations)

29. IEEE (2023) — *Ethically Aligned Design*  
    (search: IEEE Ethically Aligned Design)

---

## Animals & Non-Human Subjects in Digital Media

30. World Animal Protection (2022–2024) — *Digital exploitation of animals*  
    (search: World Animal Protection digital exploitation animals)

31. AI & Society (Springer Nature) — *Ethics of non-human representation in AI systems*  
    (search: AI & Society ethics non human representation)

---

## Technical Risks & Environmental Externalities

32. Nature/Scientific reporting (2023) — *Environmental footprint of large AI models*  
    (search: AI environmental footprint 2023 research)

33. Journal of Responsible Technology (2024) — *Energy and resource impact of generative AI*  
    (search: Journal Responsible Technology AI impact energy water)

---

## Notes on Citation Use

- References are **indicative, not exhaustive**.  
- Search terms are provided to support verification when URLs are unavailable.  
- Harmful content itself is intentionally not linked.  
- This list supports UCSF v1.0 and may expand based on peer feedback.