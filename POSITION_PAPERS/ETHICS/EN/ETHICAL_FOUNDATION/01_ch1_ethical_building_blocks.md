<a id="ch1"></a>
# Chapter 1 — Ethical Building Blocks

Before we can meaningfully engage with AI, systems, responsibility, and protection, we must slow down.

Not to revisit technical fundamentals,  
but to pause on something more basic:

*what do we actually mean by ethics?*

I understand ethics as something deeply interwoven with everyday life — with how we act, what we normalize, and the responsibilities we carry.

In its simplest form, ethics concerns the daily choices we make. One might imagine it as a background process — *ethics.exe* — quietly running in the mind, orienting moral judgment.

Reality is, of course, far more complex.

But the metaphor provides an entry point.

What is the right thing to do?  
What causes harm?  
Where does my responsibility begin — and where does another’s?  
Who is affected by my decisions?

Ethics is not a checklist.

It is a form of attentiveness: to action, consequence, and relationship.

It is less about perfect answers than about sustained care — for those impacted, for what is vulnerable, and for the responsibilities we carry even when unseen.

Everyone practices ethics, consciously or not.

Every small act carries moral weight: helping or passing by, buying or refraining, speaking or remaining silent. Individually mundane, collectively they constitute the moral fabric of daily life.

Life is saturated with ethics.

---

A cultural illustration appears in *The Good Place*, where a single question repeatedly surfaces:

**What do we owe each other?**

This formulation originates in the work of T. M. Scanlon, whose philosophy centers on mutual justification.

Ethics, in this view, is not about maximizing outcomes or applying abstract formulas, but about what we can reasonably justify to one another.

Not merely what is possible,  
but what we may legitimately do to each other — and what we may not.

---

## Ethics is not a luxury

Ethics is often treated as abstract — something reserved for philosophers, committees, or policy frameworks.

In practice, it operates at the smallest scale.

In everyday interactions.  
In default settings.  
In visibility and erasure.  
In who receives protection — and who is left to cope alone.

Ethics typically becomes explicit only once something breaks.

But it belongs *before* harm occurs.

Not as an afterthought.  
As a foundation.

---

## From personal choice to systems

Traditionally, ethics addressed individual behavior.

What should *I* do?

In a world increasingly shaped by digital infrastructure, the question shifts:

What are *we* building?

Modern systems steer behavior, shape attention, influence preference, determine visibility, and automate decisions — silently, at scale, often beyond immediate human awareness.

Responsibility migrates from individuals to architecture.

Users make choices.

So do designers.  
Product teams.  
Platforms.  
Business models.

Ethics moves from the personal to the structural.

---

## Technology is not neutral

Technology is not neutral.

Every tool embeds assumptions: about value, efficiency, centrality, and acceptable risk.

Once systems scale, those assumptions scale with them.

A minor design choice can suddenly affect millions.

This is why ethics in technology is not peripheral.

It is foundational.

---

## Not everything that can be done should be done

A core principle throughout this work — and later within UCSF — is simple:

Technical possibility does not imply moral desirability.

Progress without reflection becomes blind optimization.

Optimization without care displaces harm elsewhere in the system.

Ethics prevents “can” from automatically becoming “must.”

---

## From rules to care

This work begins not only with moral rules, but with care.

Care for vulnerability.  
Care for identity.  
Care for mental space.  
Care for future consequences.

Here, ethics is not framed as a constraint on creativity, but as protection of humanity.

When we later speak of consent, safety, identity, intent, and fail-closed systems, we do so from this foundation:

that people are not means,  
that vulnerability warrants protection,  
and that systems themselves carry responsibility.

---

---

[← Back to table of contents](contents.md) | [Next chapter →](02_ch2_moral_foundations_of_ucsf.md)