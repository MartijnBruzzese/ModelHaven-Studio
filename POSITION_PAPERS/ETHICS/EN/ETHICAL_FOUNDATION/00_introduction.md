<a id="introduction"></a>
# Introduction

“Ethical Artificial Intelligence.”  
“Responsible AI.”  
“Alignment.”  
“Governance.”  
“Prompt engineering.”  
“Vibe coding.”  
“AI influencers.”

The vocabulary keeps expanding. At some point, listing it becomes futile — we might as well compile a dictionary.

These terms have quietly embedded themselves into everyday life, much like earlier concepts such as internet, social media, big data, algorithms, platform economies, engagement, and monetization.

Every major technological shift generates its own language.

This is not new.

The automobile.  
The refrigerator.  
The gas stove.  
The microwave.  
The air fryer.

Each innovation reshaped daily routines: how we move, how we cook, how we organize time, how we inhabit space. With every technological advance came new habits, new assumptions, and new ways of perceiving the world.

Since the industrial revolution, the pattern repeats itself: new machines, new processes — and new vocabularies.

These words do more than describe technology. They gradually reshape perception itself.

From steam power to electricity.  
From factories to networks.  
From mass production to mass data extraction.

Where power once revolved around physical labor, it now increasingly concentrates around attention, behavior, and information — and around those who control, analyze, and monetize these flows.

Each phase introduces new promises, and new asymmetries.

Technology does not merely change what we do.  
It changes how we think.

Today this manifests in a culture that celebrates “disruption,” treats scalability as inevitability, and frames optimization as virtue — while human consequences often become visible only after systems have already gone global.

The current wave of artificial intelligence, including Large Language Models (LLMs), fits seamlessly into this historical trajectory.

Development moves at breathtaking speed — so fast that writing about it risks becoming outdated mid-paragraph.

And yet reflection remains essential.

Because to understand where we are heading, we must first understand where we came from — and where we currently stand.

Ethics — the question of what is right, and why — does not expire.

It forms the foundation of how we relate to one another, to institutions, and to the world itself.

In the early phases of platform development, ethical reflection was rarely central. Design discussions prioritized speed, scale, and market capture. Only gradually has awareness emerged that this trajectory is unsustainable — unevenly, and often only once harm becomes visible.

Not out of malice, but because systems evolve within economic incentives that reward growth and penalize restraint.

Every keystroke is logged.  
Behavior is analyzed through trackers, cookies, and predictive patterns.  
All driven by what might be called the Great Algorithm — now amplified by artificial intelligence.

Identity and self-image increasingly take shape within this machinery.

Who determines what we buy?  
What we prefer?  
What we overlook?

We consume what is presented to us, while those same interactions are recursively fed back into systems designed to anticipate our next move.

Gradually, we have become:

products.  
datasets.  
training material.

This may sound apocalyptic.

At times, it is.

But it is neither entirely catastrophic nor entirely benign.

The issue is not technology itself.

The issue is scale without ethics.

Which brings us to a deceptively simple question:

not whether something *can* be done —  
but whether it *should*.

Must every technical possibility be pursued?

When did progress stop demanding wisdom?

How many shareholders still need to be satisfied before we acknowledge that humanity itself holds the largest stake in the condition of this planet?

These may not sound like technical questions.

They are unavoidable nonetheless.

Because ultimately, everything returns to ethics.

This is where UCSF and ModelHaven Studio begin.

In this document, I examine my own ethical foundations and explore how they inform the principles underlying UCSF.

---

[← Back to table of contents](contents.md) | [Next chapter →](01_ch1_ethical_building_blocks.md)