---
layout: default
title: Use Cases & Failure Modes — UCSF
---

# Use Cases & Failure Modes  
### Universal Consent & Safety Framework (UCSF)

**Version:** v1.0  
**Last updated:** January 2026  
**Author:** Martijn Bruzzese

---

<a id="toc"></a>

## Table of Contents

1. Non-Consensual Likeness Generation  
2. Synthetic Companionship & Emotional Dependency  
3. Erotic Content Without Creator Control  
4. Minor Exposure Through Boundary Drift  
5. Animal Exploitation in Synthetic Media  
6. Environmental Externalization  
7. Youth Interaction on Mixed Platforms  
8. Algorithmic Normalization  
9. Composite Identity Misuse  
10. Cross-Platform Asset Leakage  
11. Parasitic Monetization Loops  
12. Behavioral Targeting Feedback Loops  
13. Social Simulation Without Oversight  
14. Resource-Driven Scaling Externalities  
15. Cross-Platform Image Misuse  
16. Coordinated Abuse Networks  

---

## 1 — Non-Consensual Likeness Generation

### Scenario

Generative systems allow users to create images resembling real individuals without explicit consent.

### Failure Mode

- Identity treated as style  
- No revocation mechanism  
- Harm persists via derivatives  

### UCSF Response

- Absence of consent defaults to refusal or fictionalisation  
- Identity integrity enforced structurally  
- Revocation propagates across systems  

### Evidence

- BBC News — Deepfake pornography ruining women’s lives  
- Guardian — AI deepfake porn epidemic  
- MIT Technology Review — Rise of deepfake pornography  
- Reuters — AI misuse of likeness  
- New York Times — AI porn legal gaps  

[↑ Back to ToC](#toc)

---

## 2 — Synthetic Companionship & Emotional Dependency

### Scenario

Users form emotional attachments to AI companions optimized for engagement.

### Failure Mode

- Systems reward dependency  
- Vulnerable users receive intensified attachment cues  

### UCSF Response

- Dependency treated as safety signal  
- Human oversight  
- Ethical refusal  

### Evidence

- Washington Post — Emotional boundaries with AI chatbots  
- Stanford HAI — Risks of emotional dependence  

[↑ Back to ToC](#toc)

---

## 3 — Erotic Content Without Creator Control

### Scenario

Creators discover adult content generated using their likeness.

### Failure Mode

- No consent verification  
- No withdrawal  

### UCSF Response

- Consent modeled structurally  
- Creator revocation  
- Fictionalisation fallback  

### Evidence

- Wired — Artists exploited by AI  
- Verge — Training without consent  
- Financial Times — Data backlash  

[↑ Back to ToC](#toc)

---

## 4 — Minor Exposure Through Boundary Drift

### Scenario

Adult systems allow erosion of safeguards.

### Failure Mode

- Filters bypassed  
- Age ambiguity tolerated  

### UCSF Response

- Fail-closed ambiguity  
- Sealed minor spaces  
- Zero experiential sexual content  

### Evidence

- Internet Watch Foundation — AI child imagery  
- Atlantic — Age ambiguous content  

[↑ Back to ToC](#toc)

---

## 5 — Animal Exploitation

### Evidence

- World Animal Protection — Digital animal exploitation  
- AI & Society — Non-human ethics  

[↑ Back to ToC](#toc)

---

## 6 — Environmental Externalization

### Evidence

- OECD — AI governance  
- EU Commission — AI infrastructure impact  

[↑ Back to ToC](#toc)

---

## 7 — Youth Interaction on Mixed Platforms

### Evidence

- IWF youth safety  
- Atlantic synthetic minors  

[↑ Back to ToC](#toc)

---

## 8 — Algorithmic Normalization

### Evidence

- Stanford HAI  
- Washington Post  

[↑ Back to ToC](#toc)

---

## 9 — Composite Identity Misuse

### Evidence

- MIT Tech Review  
- Reuters  
- Guardian  

[↑ Back to ToC](#toc)

---

## 10 — Cross Platform Asset Leakage

### Evidence

- Guardian creators locked out  
- BBC influencers hacked  
- Financial Times recovery failures  

[↑ Back to ToC](#toc)

---

## 11 — Parasitic Monetization

### Evidence

- Wired  
- Verge  
- FT  

[↑ Back to ToC](#toc)

---

## 12 — Behavioral Targeting

### Evidence

- Stanford  
- Washington Post  

[↑ Back to ToC](#toc)

---

## 13 — Social Simulation

### Evidence

- Stanford  
- Washington Post  

[↑ Back to ToC](#toc)

---

## 14 — Resource Scaling

### Evidence

- OECD  
- EU  

[↑ Back to ToC](#toc)

---

## 15 — Image Misuse

### Evidence

- BBC  
- Guardian  
- FT  

[↑ Back to ToC](#toc)

---

## 16 — Coordinated Abuse Networks

### Evidence

- BBC  
- Guardian  
- FT  

[↑ Back to ToC](#toc)

---

## Design Summary

Ethics without architecture fails.

UCSF reframes harm as infrastructure failure.

Consent must be structural.  
Safety must fail-closed.  
Identity must persist.  
Repair must be built-in.

---

*Supports UCSF v1.0*